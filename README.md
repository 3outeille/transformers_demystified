# transformers_demystified

- Config:
    - Ubuntu 20.04.5 LTS
    - torch 1.11.0
    - Cuda 11.4 (cuda for torch wheel 11.3 >= works too)
- When creating custom kernel/env for jupyter notebook, do not forget to activate env before running `python -m ipykernel install --user --name=env`
---
# TODO: 

- [**:fire: "Thinking like Transformers": framework to simulate Transformer computations. The resulting language RASP is a programming language where every program compiles down to a specific Transformer => Useful to gain intuition :fire:**](https://srush.github.io/raspy/)
- CNN without attention: [Neural Machine Translation in Linear Time](https://arxiv.org/abs/1610.10099)
    - https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb
- CNN  + attention: [paper "Convolutional Sequence to Sequence Learning"](https://arxiv.org/pdf/1705.03122.pdf)
    - install torch==1.8 and torchtext==0.9 to understand structure of dataset
    - https://github.com/bentrevett/pytorch-seq2seq/blob/master/5%20-%20Convolutional%20Sequence%20to%20Sequence%20Learning.ipynb
    - [WaveNet implemented by Kaparthy :fire:](https://www.youtube.com/watch?v=t3YJ5hKiMQ0)
---

# HackMd links

- [Language modeling & Text classification & Seq2Seq & Attention](https://hackmd.io/5IXrMYA4S86B1zYCUFdlfg)
- [OFFICIAL "Demistify Transformers attention mechanism"](https://hackmd.io/5W355qC3RRCnw4NtJ0FFLw)
- [Transformer (math)](https://hackmd.io/wbuEpc-1TjiDx-VV0S-qyQ)
- [Draft "Demistify Transformers attention mechanism"](https://hackmd.io/lKZEd1uCTSu8d4z2MYeQ2A)
- [Transformers](https://hackmd.io/R1VL6xwaRyWuLcavBWJ3gA)
- [Review on Transformers](https://hackmd.io/7hMDlKqNQBaVFH1OjPOh4w)
- [Transformers ressources](https://hackmd.io/9ky-n4HyQpyyd-zHTTwjhw)
- [Attention ? Attention !](https://hackmd.io/kbKcFkg1QQ2zL3qJyOREww)
